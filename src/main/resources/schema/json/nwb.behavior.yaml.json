{
    "groups": [
        {
            "doc": "Direction, e.g., of gaze or travel, or position. The TimeSeries::data field is a 2D array storing position or direction relative to some reference frame. Array structure: [num measurements] [num dimensions]. Each SpatialSeries has a text dataset reference_frame that indicates the zero-position, or the zero-axes for direction. For example, if representing gaze direction, \"straight-ahead\" might be a specific pixel on the monitor, or some other point in space. For position data, the 0,0 point might be the top-left corner of an enclosure, as viewed from the tracking camera. The unit of data will indicate how to interpret SpatialSeries values.", 
            "attributes": [
                {
                    "doc": "Value is 'Stores points in space over time. The data[] array structure is [num samples][num spatial dimensions]'", 
                    "name": "help", 
                    "value": "Stores points in space over time. The data[] array structure is [num samples][num spatial dimensions]", 
                    "dtype": "text"
                }
            ], 
            "neurodata_type_def": "SpatialSeries", 
            "datasets": [
                {
                    "dims": [
                        "num_times", 
                        "num_features"
                    ], 
                    "shape": [
                        null, 
                        null
                    ], 
                    "name": "data", 
                    "dtype": "number", 
                    "doc": "2-D array storing position or direction relative to some reference frame.", 
                    "attributes": [
                        {
                            "default_value": "meter", 
                            "doc": "The base unit of measure used to store data. This should be in the SI unit. COMMENT: This is the SI unit (when appropriate) of the stored data, such as Volts. If the actual data is stored in millivolts, the field 'conversion' below describes how to convert the data to the specified SI unit.", 
                            "required": false, 
                            "name": "unit", 
                            "dtype": "text"
                        }
                    ]
                }, 
                {
                    "doc": "Description defining what exactly 'straight-ahead' means.", 
                    "dtype": "text", 
                    "name": "reference_frame", 
                    "quantity": "?"
                }
            ], 
            "neurodata_type_inc": "TimeSeries"
        }, 
        {
            "neurodata_type_inc": "NWBContainer", 
            "groups": [
                {
                    "doc": "IntervalSeries object containing start and stop times of epochs", 
                    "neurodata_type_inc": "IntervalSeries", 
                    "quantity": "*"
                }
            ], 
            "attributes": [
                {
                    "doc": "Value is 'General container for storing behavorial epochs'", 
                    "name": "help", 
                    "value": "General container for storing behavorial epochs", 
                    "dtype": "text"
                }
            ], 
            "doc": "TimeSeries for storing behavoioral epochs.  The objective of this and the other two Behavioral interfaces (e.g. BehavioralEvents and BehavioralTimeSeries) is to provide generic hooks for software tools/scripts. This allows a tool/script to take the output one specific interface (e.g., UnitTimes) and plot that data relative to another data modality (e.g., behavioral events) without having to define all possible modalities in advance. Declaring one of these interfaces means that one or more TimeSeries of the specified type is published. These TimeSeries should reside in a group having the same name as the interface. For example, if a BehavioralTimeSeries interface is declared, the module will have one or more TimeSeries defined in the module sub-group \"BehavioralTimeSeries\". BehavioralEpochs should use IntervalSeries. BehavioralEvents is used for irregular events. BehavioralTimeSeries is for continuous data.", 
            "neurodata_type_def": "BehavioralEpochs", 
            "default_name": "BehavioralEpochs"
        }, 
        {
            "neurodata_type_inc": "NWBContainer", 
            "groups": [
                {
                    "doc": "TimeSeries object containing irregular behavioral events", 
                    "neurodata_type_inc": "TimeSeries", 
                    "quantity": "*"
                }
            ], 
            "attributes": [
                {
                    "doc": "Value is 'Position data, whether along the x, xy or xyz axis'", 
                    "name": "help", 
                    "value": "Position data, whether along the x, xy or xyz axis", 
                    "dtype": "text"
                }
            ], 
            "doc": "TimeSeries for storing behavioral events. See description of <a href=\"#BehavioralEpochs\">BehavioralEpochs</a> for more details.", 
            "neurodata_type_def": "BehavioralEvents", 
            "default_name": "BehavioralEvents"
        }, 
        {
            "neurodata_type_inc": "NWBContainer", 
            "groups": [
                {
                    "doc": "TimeSeries object containing continuous behavioral data", 
                    "neurodata_type_inc": "TimeSeries", 
                    "quantity": "*"
                }
            ], 
            "attributes": [
                {
                    "doc": "Value is 'General container for storing continuously sampled behavioral data.'", 
                    "name": "help", 
                    "value": "General container for storing continuously sampled behavioral data.", 
                    "dtype": "text"
                }
            ], 
            "doc": "TimeSeries for storing Behavoioral time series data.See description of <a href=\"#BehavioralEpochs\">BehavioralEpochs</a> for more details.", 
            "neurodata_type_def": "BehavioralTimeSeries", 
            "default_name": "BehavioralTimeSeries"
        }, 
        {
            "neurodata_type_inc": "NWBContainer", 
            "groups": [
                {
                    "doc": "TimeSeries object containing time series data on pupil size", 
                    "neurodata_type_inc": "TimeSeries", 
                    "quantity": "+"
                }
            ], 
            "attributes": [
                {
                    "doc": "Value is 'Eye-tracking data, representing pupil size'", 
                    "name": "help", 
                    "value": "Eye-tracking data, representing pupil size", 
                    "dtype": "text"
                }
            ], 
            "doc": "Eye-tracking data, representing pupil size.", 
            "neurodata_type_def": "PupilTracking", 
            "default_name": "PupilTracking"
        }, 
        {
            "neurodata_type_inc": "NWBContainer", 
            "groups": [
                {
                    "doc": "SpatialSeries object containing data measuring direction of gaze", 
                    "neurodata_type_inc": "SpatialSeries", 
                    "quantity": "*"
                }
            ], 
            "attributes": [
                {
                    "doc": "Value is 'Eye-tracking data, representing direction of gaze'", 
                    "name": "help", 
                    "value": "Eye-tracking data, representing direction of gaze", 
                    "dtype": "text"
                }
            ], 
            "doc": "Eye-tracking data, representing direction of gaze.", 
            "neurodata_type_def": "EyeTracking", 
            "default_name": "EyeTracking"
        }, 
        {
            "neurodata_type_inc": "NWBContainer", 
            "groups": [
                {
                    "doc": "SpatialSeries object containing direction of gaze travel", 
                    "neurodata_type_inc": "SpatialSeries", 
                    "quantity": "*"
                }
            ], 
            "attributes": [
                {
                    "doc": "Value is 'Direction as measured radially. Spatial series reference frame should indicate which direction corresponds to zero and what is the direction of positive rotation'", 
                    "name": "help", 
                    "value": "Direction as measured radially. Spatial series reference frame should indicate which direction corresponds to zero and what is the direction of positive rotation", 
                    "dtype": "text"
                }
            ], 
            "doc": "With a CompassDirection interface, a module publishes a SpatialSeries object representing a floating point value for theta. The SpatialSeries::reference_frame field should indicate what direction corresponds to 0 and which is the direction of rotation (this should be clockwise). The si_unit for the SpatialSeries should be radians or degrees.", 
            "neurodata_type_def": "CompassDirection", 
            "default_name": "CompassDirection"
        }, 
        {
            "neurodata_type_inc": "NWBContainer", 
            "groups": [
                {
                    "doc": "SpatialSeries object containing position data", 
                    "neurodata_type_inc": "SpatialSeries", 
                    "quantity": "+"
                }
            ], 
            "attributes": [
                {
                    "doc": "Value is 'Position data, whether along the x, xy or xyz axis'", 
                    "name": "help", 
                    "value": "Position data, whether along the x, xy or xyz axis", 
                    "dtype": "text"
                }
            ], 
            "doc": "Position data, whether along the x, x/y or x/y/z axis.", 
            "neurodata_type_def": "Position", 
            "default_name": "Position"
        }, 
        {
            "neurodata_type_inc": "NWBContainer", 
            "groups": [
                {
                    "neurodata_type_inc": "NWBContainer", 
                    "groups": [
                        {
                            "doc": "Image stack with frames shifted to the common coordinates.", 
                            "neurodata_type_inc": "ImageSeries", 
                            "name": "corrected"
                        }, 
                        {
                            "doc": "Stores the x,y delta necessary to align each frame to the common coordinates, for example, to align each frame to a reference image.", 
                            "neurodata_type_inc": "TimeSeries", 
                            "name": "xy_translation"
                        }
                    ], 
                    "links": [
                        {
                            "doc": "HDF5 Link to image series that is being registered.", 
                            "name": "original", 
                            "target_type": "ImageSeries"
                        }
                    ], 
                    "attributes": [
                        {
                            "doc": "Value is 'Reuslts from motion correction of an image stack'", 
                            "name": "help", 
                            "value": "Reuslts from motion correction of an image stack", 
                            "dtype": "text"
                        }
                    ], 
                    "doc": "One of possibly many.  Name should be informative.", 
                    "neurodata_type_def": "CorrectedImageStack", 
                    "quantity": "+"
                }
            ], 
            "attributes": [
                {
                    "doc": "Value is 'Image stacks whose frames have been shifted (registered) to account for motion'", 
                    "name": "help", 
                    "value": "Image stacks whose frames have been shifted (registered) to account for motion", 
                    "dtype": "text"
                }
            ], 
            "doc": "An image stack where all frames are shifted (registered) to a common coordinate system, to account for movement and drift between frames. Note: each frame at each point in time is assumed to be 2-D (has only x & y dimensions).", 
            "neurodata_type_def": "MotionCorrection", 
            "default_name": "MotionCorrection"
        }
    ]
}